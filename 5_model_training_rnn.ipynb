{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Initilization"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\"\"\"\n","DATA COLLECTION\n","\"\"\"\n","\n","import requests, zipfile, io\n","url = 'https://github.com/rgap/NMA-Twitter-SentimentAnalysis/raw/main/data/raw/trainingandtestdata.zip'\n","raw_data_directory = 'data/raw/'\n","r = requests.get(url)\n","z = zipfile.ZipFile(io.BytesIO(r.content))\n","z.extractall(path=raw_data_directory)\n","\n","\n","# Read the dataset\n","\n","import pandas as pd\n","raw_data_directory = 'data/raw/'\n","# We load the dataset (THIS WILL USE ONLY THE TRAINING DATASET)\n","header_list = [\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n","df = pd.read_csv(raw_data_directory + 'training.1600000.processed.noemoticon.csv',\n","                 encoding = \"ISO-8859-1\", names=header_list)\n","# Let's have a look at it\n","df.head(2)\n","\n","\"\"\"\n","DATA PREPROCESSING\n","\"\"\"\n","\n","# Features\n","features = ['id', 'date', 'query', 'user', 'text']\n","# Target\n","target = 'polarity'\n","\n","# Transform the polarity column into just 0s and 1s because it has only 2 unique values and the column type should be int\n","df['polarity'] = df['polarity'].apply(lambda x: 0 if x == 0 else 1)"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Engineering Initialization"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = df.text.values\n","y = df.polarity.values\n","\n","# Split the data into train and test\n","x_train_text, x_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n","\n","# Feature engineering\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","vectorizer = CountVectorizer()\n","vectorizer.fit(x_train_text)\n","x_train_count_vectorizer = vectorizer.transform(x_train_text)"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Model Selection"]},{"cell_type":"markdown","metadata":{},"source":["### Testing an RNN"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"]}],"source":["# import torch\n","import torch\n","\n","def set_device():\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  if device != \"cuda\":\n","    print(\"WARNING: For this notebook to perform best, \"\n","          \"if possible, in the menu under `Runtime` -> \"\n","          \"`Change runtime type.`  select `GPU` \")\n","  else:\n","    print(\"GPU is enabled in this notebook.\")\n","\n","  return device\n","\n","# Set the device (check if gpu is available)\n","device = set_device()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'sorted_words' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# From previous section, we have a list with the most used tokens\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msorted_words\u001b[49m[:\u001b[38;5;241m10\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'sorted_words' is not defined"]}],"source":["# From previous section, we have a list with the most used tokens\n","sorted_words[:10]"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"twitter_nlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
