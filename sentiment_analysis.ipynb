{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>   <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/projects/NaturalLanguageProcessing/sentiment_analysis.ipynb\" target=\"_blank\"><img alt=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "# 1. Questions\n",
    "\n",
    "* Can we infer emotion from a tweet text?\n",
    "* How words are distributed accross the dataset?\n",
    "* Are words related to one kind of emotion?\n",
    "\n",
    "# 2. Literature review\n",
    "\n",
    "[Original Dataset Paper](https://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf)\n",
    "\n",
    "[Papers with code](https://paperswithcode.com/dataset/imdb-movie-reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# 3. Load and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import some libraries to load the dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/twitter_nlp/lib/python3.12/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "You can find the dataset we are going to use in [this website](http://help.sentiment140.com/for-students/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "url = 'https://github.com/rgap/NMA-Twitter-SentimentAnalysis/raw/main/data/raw/trainingandtestdata.zip'\n",
    "raw_data_directory = 'data/raw/'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(path=raw_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the dataset\n",
    "header_list = [\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "df = pd.read_csv(raw_data_directory + 'training.1600000.processed.noemoticon.csv',\n",
    "                 encoding = \"ISO-8859-1\", names=header_list)\n",
    "\n",
    "# Let's have a look at it\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For this project we will use only the text and the polarity of the tweet. Notice that polarity is 0 for negative tweets and 4 for positive tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text.values\n",
    "\n",
    "# Changes values from [0,4] to [0,1]\n",
    "y = (df.polarity.values > 1).astype(int)\n",
    "\n",
    "\n",
    "# Split the data into train and test\n",
    "x_train_text, x_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The first thing we have to do before working on the models is to familiarize ourselves with the dataset. This is called Exploratory Data Analisys (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: @paisleypaisley LOL why do i get ideas so far in advance? it's not even june yet! we need a third knitter to have our own summer group \n",
      "0: worst headache ever \n",
      "0: @ewaniesciuszko  i am so sad i wont see you! I miss you already. and yeah! that's perfect; i come back the 18th!\n",
      "1: doesn't know how to spell conked \n",
      "0: &quot;So we stand here now and no one knows us at all I won't get used to this I won't get used to being gone&quot;...I miss home and everyone  -a\n"
     ]
    }
   ],
   "source": [
    "for s, l in zip(x_train_text[:5], y_train[:5]):\n",
    "  print('{}: {}'.format(l, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "An interesting thing to analyze is the Word Distribution. In order to count the occurrences of each word, we should tokenize the sentences first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Tokenize:  worst headache ever \n",
      "After Tokenize:  ['worst', 'headache', 'ever']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "print('Before Tokenize: ', x_train_text[1])\n",
    "print('After Tokenize: ', tokenizer(x_train_text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd88842c1b114c58b6cfe2beddf63a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77d933efdc0480ca0ab034da8bda7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_token = [tokenizer(s) for s in tqdm(x_train_text)]\n",
    "x_test_token = [tokenizer(s) for s in tqdm(x_test_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We can count the words occurences and see how many different words are present in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different Tokens in our Dataset: 669284\n",
      "['.', 'i', '!', \"'\", 'to', 'the', ',', 'a', 'my', 'it', 'and', 'you', '?', 'is', 'for', 'in', 's', 'of', 't', 'on', 'that', 'me', 'so', 'have', 'm', 'but', 'just', 'with', 'be', 'at', 'not', 'was', 'this', 'now', 'can', 'good', 'up', 'day', 'all', 'get', 'out', 'like', 'are', 'no', 'go', 'http', '-', 'today', 'do', 'too', 'your', 'work', 'going', 'love', 'we', 'got', 'what', 'lol', 'time', 'back', 'from', 'u', 'one', 'will', 'know', 'about', 'im', 'really', 'don', 'am', 'had', ')', 'see', 'some', 'there', 'its', '&amp', 'how', 'if', 'still', 'they', '&quot', 'night', '(', 'well', 'want', 'new', 'think', '2', 'home', 'thanks', 'll', 'oh', 'when', 'as', 'he', 'more', 'here', 'much', 'off']\n"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "for s in x_train_token:\n",
    "  for w in s:\n",
    "    words[w] += 1\n",
    "\n",
    "sorted_words = list(words.keys())\n",
    "sorted_words.sort(key=lambda w: words[w], reverse=True)\n",
    "print(f\"Number of different Tokens in our Dataset: {len(sorted_words)}\")\n",
    "print(sorted_words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can plot their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0.13970153178620734% most common words account for the 80.00532743602652% of the occurrences\n"
     ]
    }
   ],
   "source": [
    "count_occurences = sum(words.values())\n",
    "\n",
    "accumulated = 0\n",
    "counter = 0\n",
    "\n",
    "while accumulated < count_occurences * 0.8:\n",
    "  accumulated += words[sorted_words[counter]]\n",
    "  counter += 1\n",
    "\n",
    "print(f\"The {counter * 100 / len(words)}% most common words \"\n",
    "      f\"account for the {accumulated * 100 / count_occurences}% of the occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(100), [words[w] for w in sorted_words[:100]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "It is very common to find this kind of distribution when analyzing corpus of text. This is referred to as the [zipf's law](https://en.wikipedia.org/wiki/Zipf%27s_law)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Usually the number of words in the dictionary will be very large. \n",
    "\n",
    "Here are some thing we can do to reduce that number:\n",
    "\n",
    "* Remove puntuation.\n",
    "* Remove stop-words.\n",
    "* Steaming.\n",
    "* Remove very uncommon words (the words that appears in fewer than N occations).\n",
    "* Nothing: we can use a pretrain model that handles this kind of situations.\n",
    "\n",
    "\n",
    "We used one of the simplest tokenizers availables. This tokenizer does not take into account many quirks of the language. Moreover, diferent languages have different quirks, so there is no \"universal\" tokenizers. There are many libraries that have \"better\" tokenizers:\n",
    "\n",
    "* [Spacy](https://spacy.io/): it can be accessed using: `get_tokenizer(\"spacy\")`. Spacy supports a wide range of languages.\n",
    "* [Huggingface](https://huggingface.co/): it has many tokenizers for different laguages. [Doc](https://huggingface.co/transformers/main_classes/tokenizer.html)\n",
    "* [NLTK](https://www.nltk.org/): it provides several tokenizers. One of them can be accessed using: `get_tokenizer(\"toktok\")`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Step 4: choose toolkit\n",
    "\n",
    "Our goal is to train a model capable of estimating the sentiment of a tweet (positive or negative) by reading its content. To that end we will try 2 different approaches:\n",
    "\n",
    "* A logistic regression using sklearn. **NOTE**: it can probaly work better than an SVM model.\n",
    "* A simple Embedding + RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "We will represent our senteces using binary vectorization. This means that our data would be represented as a matrix of instances by word with a one if the word is in the instance, and zero otherwise. Sklean vectorizers can also do things such as stop-word removal and puntuation removal, you can read more about in [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True)\n",
    "x_train_cv = vectorizer.fit_transform(x_train_text)\n",
    "x_test_cv = vectorizer.transform(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Vectorize:  doesn't know how to spell conked \n"
     ]
    }
   ],
   "source": [
    "print('Before Vectorize: ', x_train_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Vectorize: \n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 6 stored elements and shape (1, 589260)>\n",
      "  Coords\tValues\n",
      "  (0, 528584)\t1\n",
      "  (0, 165468)\t1\n",
      "  (0, 300381)\t1\n",
      "  (0, 242211)\t1\n",
      "  (0, 489893)\t1\n",
      "  (0, 134160)\t1\n"
     ]
    }
   ],
   "source": [
    "# Notice that the matriz is sparse\n",
    "print('After Vectorize: ')\n",
    "print(x_train_cv[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now we can train our model. You can check the documentation of this logistic regressor [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic#sklearn.linear_model.LogisticRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='saga')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='saga')\n",
    "model.fit(x_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80    160000\n",
      "           1       0.79      0.81      0.80    160000\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_cv)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Explainable AI\n",
    "The best thing about logistic regresion is that it is simple, and we can get some explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 589260)\n",
      "589260\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_.shape)\n",
    "print(len(vectorizer.vocabulary_))\n",
    "\n",
    "words_sk = list(vectorizer.vocabulary_.keys())\n",
    "words_sk.sort(key=lambda w: model.coef_[0, vectorizer.vocabulary_[w]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roni: -3.8625977127123017\n",
      "inaperfectworld: -3.573439309207433\n",
      "dontyouhate: -3.5001974329187484\n",
      "xbllygbsn: -3.4126517021915874\n",
      "anqju: -3.336434953837981\n",
      "sad: -3.20052276385081\n",
      "pakcricket: -3.194904159349193\n",
      "condolences: -3.132571641791495\n",
      "heartbreaking: -3.066491697545889\n",
      "saddest: -3.0420156544550507\n",
      "sadd: -3.0290862314909974\n",
      "heartbroken: -3.0287774670135006\n",
      "boohoo: -3.0226092379659093\n",
      "sadface: -2.9918269087948715\n",
      "rachelle_lefevr: -2.9250573739390635\n",
      "disappointing: -2.902521702804541\n",
      "lvbu: -2.8947204912713054\n",
      "saddens: -2.8855055418516273\n",
      "bummed: -2.8365025968652526\n",
      "neda: -2.7929637927459545\n"
     ]
    }
   ],
   "source": [
    "for w in words_sk[:20]:\n",
    "  print('{}: {}'.format(w, model.coef_[0, vectorizer.vocabulary_[w]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iamsoannoyed: 2.849418562659857\n",
      "myfax: 2.7975535743717175\n",
      "jennamadison: 2.5667189970142155\n",
      "yeyy: 2.478046434230527\n",
      "tryout: 2.4383298813412733\n",
      "goldymom: 2.43740090297448\n",
      "wooohooo: 2.4029544497168565\n",
      "thesupergirl: 2.356512377836073\n",
      "iammaxathotspot: 2.3116596881411513\n",
      "londicreations: 2.307446416241598\n",
      "smilin: 2.2991710760941095\n",
      "worries: 2.289938773025935\n",
      "sinfulsignorita: 2.2798963402588064\n",
      "finchensnail: 2.264330018555255\n",
      "smackthis: 2.2376644717780074\n",
      "kv: 2.215832767889474\n",
      "tojosan: 2.2117969882895427\n",
      "russmarshalek: 2.2095439877272702\n",
      "traciknoppe: 2.1768390813081755\n",
      "congratulations: 2.171589271346398\n"
     ]
    }
   ],
   "source": [
    "for w in reversed(words_sk[-20:]):\n",
    "  print('{}: {}'.format(w, model.coef_[0, vectorizer.vocabulary_[w]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "What does this mean?\n",
    "\n",
    "Remember the `model.coef_` is the $W$ in:\n",
    "\n",
    "$$h(x)=\\sigma(WX + b)$$\n",
    "\n",
    "where the label 1 is a positive tweet and the label 0 is a negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Recurrent Neural Network with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the previous section we use a Bag-Of-Words approach to represent each of the tweets. That meas that we only consider how many times each of the words appear in each of the tweets, we didnt take into account the order of the words. But we know that the word order is very important and carries relevant information.\n",
    "\n",
    "In this section we will solve the same task, but this time we will implement a Recurrent Neural Network (RNN) instead of using a simple Logistic Regression.Unlike feedforward neural networks, RNNs have cyclic connections making them powerful for modeling sequences.\n",
    "\n",
    "Let's start by importing the relevant libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "          \"if possible, in the menu under `Runtime` -> \"\n",
    "          \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n"
     ]
    }
   ],
   "source": [
    "# Set the device (check if gpu is available)\n",
    "device = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "First we will create a Dictionary (`word_to_idx`). This dictionary will map each Token (usually words) to an index (an integer number). We want to limit our dictionary to a certain number of tokens (`num_words_dict`), so we will include in our ditionary those with more occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'i', '!', \"'\", 'to', 'the', ',', 'a', 'my', 'it']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From previous section, we have a list with the most used tokens\n",
    "sorted_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's select only the most used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_dict = 30000\n",
    "# We reserve two numbers for special tokens.\n",
    "most_used_words = sorted_words[:num_words_dict-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will add two extra Tokens to the dictionary, one for words outside the dictionary (`'UNK'`) and one for padding the sequences (`'PAD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to go from words to idx\n",
    "word_to_idx = {}\n",
    "# dictionary to go from idx to words (just in case)\n",
    "idx_to_word = {}\n",
    "\n",
    "\n",
    "# We include the special tokens first\n",
    "PAD_token = 0\n",
    "UNK_token = 1\n",
    "\n",
    "word_to_idx['PAD'] = PAD_token\n",
    "word_to_idx['UNK'] = UNK_token\n",
    "\n",
    "idx_to_word[PAD_token] = 'PAD'\n",
    "idx_to_word[UNK_token] = 'UNK'\n",
    "\n",
    "# We popullate our dictionaries with the most used words\n",
    "for num,word in enumerate(most_used_words):\n",
    "  word_to_idx[word] = num + 2\n",
    "  idx_to_word[num+2] = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our goal now is to transform each tweet from a sequence of tokens to a sequence of indexes. These sequences of indexes will be the input to our pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to convert list of tokens to list of indexes\n",
    "def tokens_to_idx(sentences_tokens,word_to_idx):\n",
    "  sentences_idx = []\n",
    "  for sent in sentences_tokens:\n",
    "    sent_idx = []\n",
    "    for word in sent:\n",
    "      if word in word_to_idx:\n",
    "        sent_idx.append(word_to_idx[word])\n",
    "      else:\n",
    "        sent_idx.append(word_to_idx['UNK'])\n",
    "    sentences_idx.append(sent_idx)\n",
    "  return sentences_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_idx = tokens_to_idx(x_train_token,word_to_idx)\n",
    "x_test_idx = tokens_to_idx(x_test_token,word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before converting:  ['worst', 'headache', 'ever']\n",
      "After converting:  [721, 458, 237]\n"
     ]
    }
   ],
   "source": [
    "some_number = 1\n",
    "print('Before converting: ', x_train_token[some_number])\n",
    "print('After converting: ', x_train_idx[some_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We need all the sequences to have the same length. To select an adequate sequence length, let's explore some statistics about the length of the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tweet word length:  229\n",
      "Mean tweet word length:  15.0\n",
      "99% percent under:  37.0\n"
     ]
    }
   ],
   "source": [
    "tweet_lens = np.asarray([len(sentence) for sentence in x_train_idx])\n",
    "print('Max tweet word length: ',tweet_lens.max())\n",
    "print('Mean tweet word length: ',np.median(tweet_lens))\n",
    "print('99% percent under: ',np.quantile(tweet_lens,0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We cut the sequences which are larger than our chosen maximum length (`max_lenght`) and fill with zeros the ones that are shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " # We choose the max length\n",
    " max_length = 40\n",
    "\n",
    "# A function to make all the sequence have the same lenght\n",
    "# Note that the output is a Numpy matrix\n",
    " def padding(sentences, seq_len):\n",
    "  features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "  for ii, tweet in enumerate(sentences):\n",
    "    len_tweet = len(tweet)\n",
    "    if len_tweet != 0:\n",
    "      if len_tweet <= seq_len:\n",
    "        # If its shorter, we fill with zeros (the padding Token index)\n",
    "        features[ii, -len(tweet):] = np.array(tweet)[:seq_len]\n",
    "      if len_tweet > seq_len:\n",
    "        # If its larger, we take the last 'seq_len' indexes\n",
    "        features[ii, :] = np.array(tweet)[-seq_len:]\n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert our list of tokens into a numpy matrix\n",
    "# where all instances have the same lenght\n",
    "x_train_pad = padding(x_train_idx,max_length)\n",
    "x_test_pad = padding(x_test_idx,max_length)\n",
    "\n",
    "# We convert our target list a numpy matrix\n",
    "y_train_np = np.asarray(y_train)\n",
    "y_test_np = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding:  [1, 3, 71, 24, 122, 3, 533, 74, 13, 4, 3, 102, 13, 209, 2, 12, 150, 4, 22, 5, 18, 667, 3, 138, 61, 7, 3296, 4]\n",
      "After padding:  [   0    0    0    0    0    0    0    0    0    0    0    0    1    3\n",
      "   71   24  122    3  533   74   13    4    3  102   13  209    2   12\n",
      "  150    4   22    5   18  667    3  138   61    7 3296    4]\n"
     ]
    }
   ],
   "source": [
    "some_number = 2\n",
    "print('Before padding: ', x_train_idx[some_number])\n",
    "print('After padding: ', x_train_pad[some_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, let's convert the data to pytorch format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train_np))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test_np))\n",
    "\n",
    "# Batch size (this is an important hyperparameter)\n",
    "batch_size = 100\n",
    "\n",
    "# dataloaders\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last = True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Each batch of data in our traning proccess will have the folllowing format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([100, 40])\n",
      "Sample input: \n",
      " tensor([[   0,    0,    0,  ...,  352,    2,    2],\n",
      "        [   0,    0,    0,  ..., 1546,    4,    1],\n",
      "        [   0,    0,    0,  ...,    2, 2317,  696],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    6,    7, 1973],\n",
      "        [   0,    0,    0,  ...,   14,   14,   14],\n",
      "        [   0,    0,    0,  ...,   17,  290,  161]])\n",
      "Sample input: \n",
      " tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Obtain one batch of training data\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, we will define the `SentimentRNN` class. Most of the model's class will be familiar to you, but there are two important layers we would like you to pay attention to:\n",
    "\n",
    "*   Embedding Layer\n",
    "> This layer is like a linear layer, but it makes it posible to use a sequence of inedexes as inputs (instead of a sequence of one-hot-encoded vectors). During training, the Embedding layer learns a linear transformation from the space of words (a vector space of dimension `num_words_dict`) into the a new, smaller, vector space of dimension `embedding_dim`. We suggest you to read this [thread](https://discuss.pytorch.org/t/how-does-nn-embedding-work/88518/3) and the [pytorch documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) if you want to learn more about this particular kind of layers.\n",
    "\n",
    "\n",
    "*   LSTM layer\n",
    "> This is one of the most used class of Recurrent Neural Networks. In Pytorch we can add several stacked layers in just one line of code. In our case, the number of layers added are decided with the parameter `no_layers`. If you want to learn more about LSTMs we strongly recommend you this [Colahs thread](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) about them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "  def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.1):\n",
    "    super(SentimentRNN,self).__init__()\n",
    "\n",
    "    self.output_dim = output_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.no_layers = no_layers\n",
    "    self.vocab_size = vocab_size\n",
    "    self.drop_prob = drop_prob\n",
    "\n",
    "    # Embedding Layer\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    # LSTM Layers\n",
    "    self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                        num_layers=no_layers, batch_first=True,\n",
    "                        dropout=self.drop_prob)\n",
    "\n",
    "    # Dropout layer\n",
    "    self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    # Linear and Sigmoid layer\n",
    "    self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "    self.sig = nn.Sigmoid()\n",
    "\n",
    "  def forward(self,x,hidden):\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    # Embedding out\n",
    "    embeds = self.embedding(x)\n",
    "    #Shape: [batch_size x max_length x embedding_dim]\n",
    "\n",
    "    # LSTM out\n",
    "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    # Shape: [batch_size x max_length x hidden_dim]\n",
    "\n",
    "    # Select the activation of the last Hidden Layer\n",
    "    lstm_out = lstm_out[:,-1,:].contiguous()\n",
    "    # Shape: [batch_size x hidden_dim]\n",
    "\n",
    "    ## You can instead average the activations across all the times\n",
    "    # lstm_out = torch.mean(lstm_out, 1).contiguous()\n",
    "\n",
    "    # Dropout and Fully connected layer\n",
    "    out = self.dropout(lstm_out)\n",
    "    out = self.fc(out)\n",
    "\n",
    "    # Sigmoid function\n",
    "    sig_out = self.sig(out)\n",
    "\n",
    "    # return last sigmoid output and hidden state\n",
    "    return sig_out, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    ''' Initializes hidden state '''\n",
    "    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "    # initialized to zero, for hidden state and cell state of LSTM\n",
    "    h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "    c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "    hidden = (h0,c0)\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We choose the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of our network\n",
    "\n",
    "# Size of our vocabulary\n",
    "vocab_size = num_words_dict\n",
    "\n",
    "# Embedding dimension\n",
    "embedding_dim = 32\n",
    "\n",
    "# Number of stacked LSTM layers\n",
    "no_layers = 2\n",
    "\n",
    "# Dimension of the hidden layer in LSTMs\n",
    "hidden_dim = 64\n",
    "\n",
    "# Dropout parameter for regularization\n",
    "output_dim = 1\n",
    "\n",
    "# Dropout parameter for regularization\n",
    "drop_prob = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(30000, 32)\n",
      "  (lstm): LSTM(32, 64, num_layers=2, batch_first=True, dropout=0.25)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Let's define our model\n",
    "model = SentimentRNN(no_layers, vocab_size, hidden_dim,\n",
    "                     embedding_dim, drop_prob=drop_prob)\n",
    "# Moving to gpu\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of parameters:  1018433\n"
     ]
    }
   ],
   "source": [
    "# How many trainable parameters does our model have?\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('Total Number of parameters: ',params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We choose the losses and the optimizer for the training procces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr = 0.001\n",
    "\n",
    "# Binary crossentropy is a good loss function for a binary classification problem\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# We choose an Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "  pred = torch.round(pred.squeeze())\n",
    "  return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We are ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training Epochs\n",
    "epochs = 1\n",
    "\n",
    "# Maximum absolute value accepted for the gradeint\n",
    "clip = 5\n",
    "\n",
    "# Initial Loss value (assumed big)\n",
    "valid_loss_min = np.inf\n",
    "\n",
    "# Lists to follow the evolution of the loss and accuracy\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "# Train for a number of Epochs\n",
    "for epoch in range(epochs):\n",
    "  train_losses = []\n",
    "  train_acc = 0.0\n",
    "  model.train()\n",
    "\n",
    "  for inputs, labels in train_loader:\n",
    "\n",
    "    # Initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    # Creating new variables for the hidden state\n",
    "    h = tuple([each.data.to(device) for each in h])\n",
    "\n",
    "    # Move batch inputs and labels to gpu\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Set gradient to zero\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Compute model output\n",
    "    output,h = model(inputs,h)\n",
    "\n",
    "    # Calculate the loss and perform backprop\n",
    "    loss = criterion(output.squeeze(), labels.float())\n",
    "    loss.backward()\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # calculating accuracy\n",
    "    accuracy = acc(output,labels)\n",
    "    train_acc += accuracy\n",
    "\n",
    "    #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "  # Evaluate on the validation set for this epoch\n",
    "  val_losses = []\n",
    "  val_acc = 0.0\n",
    "  model.eval()\n",
    "  for inputs, labels in valid_loader:\n",
    "\n",
    "    # Initialize hidden state\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_h = tuple([each.data.to(device) for each in val_h])\n",
    "\n",
    "    # Move batch inputs and labels to gpu\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Compute model output\n",
    "    output, val_h = model(inputs, val_h)\n",
    "\n",
    "    # Compute Loss\n",
    "    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    accuracy = acc(output,labels)\n",
    "    val_acc += accuracy\n",
    "\n",
    "  epoch_train_loss = np.mean(train_losses)\n",
    "  epoch_val_loss = np.mean(val_losses)\n",
    "  epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "  epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "  epoch_tr_loss.append(epoch_train_loss)\n",
    "  epoch_vl_loss.append(epoch_val_loss)\n",
    "  epoch_tr_acc.append(epoch_train_acc)\n",
    "  epoch_vl_acc.append(epoch_val_acc)\n",
    "  print(f'Epoch {epoch+1}')\n",
    "  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "  print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "  if epoch_val_loss <= valid_loss_min:\n",
    "    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "    # torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "    valid_loss_min = epoch_val_loss\n",
    "  print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# What's Next?\n",
    "\n",
    "You can use this project template as a starting point to think about your own project. There are a lot of ways to continue, here we share with you some ideas you migth find useful:\n",
    "\n",
    "*   **Work on the Preproccesing.** We used a very rudimentary way to tokenize tweets. But there are better ways to preprocess the data. Can you think of a suitable way to preprocess the data for this particular task? How does the performance of the model change when the data is processed correctly?\n",
    "*   **Work on the Model.** The RNN model proposed in this notebook is not optimized at all. You can work on finding a better architecture or better hyperparamenters. May be using bidirectonal LSTMs or increasing the number of stacked layers can improve the performance, feel free to try different approaches.\n",
    "*   **Work on the Embedding.** Our model learnt an embedding during the training on this Twitter corpus for a particular task. You can explore the representation of different words in this learned embedding. Also, you can try using different word embeddings. You can train them on this corpus or you can use an embedding trained on another corpus of data. How does the change of the embedding affect the model performance?\n",
    "*   **Try sentiment analysis on another dataset.** There are lots of available dataset to work with, we can help you find one that is interesting to you. Do you belive that a sentiment analysis model trained on some corpus (Twitter dataset) will perform well on another type of data (for example, youtube comments)?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "sentiment_analysis",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
